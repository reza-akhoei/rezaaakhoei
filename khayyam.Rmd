---
title: "Text Mining of Khayyam's poems using R"
author: "Reza Khoei"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

<div style="text-align: justify">

<p>
[Khayyam](https://en.wikipedia.org/wiki/Omar_Khayyam) was an Iranian astronomer, mathematician,philosopher and a poet , which is commonly known for his quatrains (short poems). He was almost unknown to whole world, till 19th century, but thanks to [**EdwardFitzGerald**](https://en.wikipedia.org/wiki/Edward_FitzGerald_(poet)), his poems were translated to English and published entitled [*Rubaiyat of Omar Khayyam*](https://en.wikipedia.org/wiki/Rubaiyat_of_Omar_Khayyam).
<p/>
<p>
Although, his achievements in astronomy and mathematics such as [solar calender](https://en.wikipedia.org/wiki/Solar_calendar) and [cubic equation](https://en.wikipedia.org/wiki/Cubic_equation) are admirable, nonetheless, world realized who he really is, because of the hidden amazing philosophy in his poems. Discovery the hidden truth in his poems made me motivated to do some analysis and document it for the others; that is exactly where the **text mining** methods come in. In text mining, the focus is on textual data and extraction of wisdom from it. To have some knowledge about text mining using *R*, you can refer to [Text Mining with R book](https://www.tidytextmining.com/) which is written by [Julia Silge](https://juliasilge.com/) and [David Robinson](http://varianceexplained.org/about/).
<p/>
<p>
Now that we have our tools, let's get ready and start our journey and float in the Khayyam's mind and find out what was going on in his mind and enjoy it.
<p/>

**Important**: Khayyam wrote these poems in Persian, but we will examine the English translated version of his poems.
<div/>

# Call required packages

At first, the packages we need, should be installed and called.

```{r eval=FALSE, message=FALSE, warning=FALSE}
install.packages(tidyverse)
install.packages(tidytext)
install.packages(gutenbergr)
install.packages(topicmodels)
install.packages(tidyr)
```


```{r message=FALSE}
library(tidyverse)
library(tidytext)
library(gutenbergr)
library(topicmodels)
```

# Download the data

<div style="text-align: justify">

So many books are accessible in the ***gutenbergr*** package. Every book has its own ***gutenberg_id*** and can be found via it. For more details you can refer to Help page of package. The ***gutenberg_id*** for Khayyam is ***246***. Let's take a look at it. 
<div/>


```{r}
khayyam <- gutenberg_download(246)
```

# Preprocessing of data

<div style="text-align: justify">
<p>
We want just the poems in the book. So sections such as introduction, preface, appendix and references must be deleted from the text. The whole text of the book is accessible with **view(khayyam)** in *RStudio*.
<p/>
<div/>

## Exclusion of non-related data

<div style="text-align: justify">
<p>
Before anything, it is better to do some data cleaning. 
As seen below, we remove and exclude rows 1:450 and 1878:2131 from our data.
<p/>
<div/>

```{r}
khayyam <- khayyam %>% slice(-c(1:450, 1878:2131))
```


## Stop words

<div style="text-align: justify">
<p>
In English (and obviously any other language), there are some words which are frequently used in every specific texts, but text analysis of them are not so useful. We called them **Stop Words**. ***R*** can detect and consider these words.
<p/>
<div/>
   
```{r}
tidy_khayyam <- khayyam %>%
    unnest_tokens(word, text) %>%
    anti_join(stop_words)
```

<div style="text-align: justify">
<p>
Below, we can look at most common words in Khayyam's poems. But, we should notice that this is without considering stop words.
<p/>
<div/>

```{r}
tidy_khayyam
# The most common words in Khayyam's poems
tidy_khayyam %>%
    count(word, sort = TRUE)
```

<div style="text-align: justify">
<p>
Additionally, we can add some words and bind them to these predefined *stop words*. For example, we customize stop words by adding words ***ah*** and ***sans***.
<p/>
<div/>

```{r}
custom_stop_words <- bind_rows(tibble(word = c("ah","sans"),  
            lexicon = c("custom")), stop_words)

custom_stop_words
```

<div style="text-align: justify">
<p>
Now, purely, we can take a look at the most frequently used words in Khayyam's poems.
<p/>
<div/>

```{r}
tidy_khayyam <- khayyam %>%
    unnest_tokens(word, text) %>%
    anti_join(custom_stop_words)
# The most common words in Khayyam's poems
tidy_khayyam %>%
    count(word, sort = TRUE)
```

<div style="text-align: justify">
<p>
**Wine**, **cup**, **rose** are 3 most common words. In the following as well, there are words such as **earth**, **dust**, **life**, **lip**  and etc. Well, what are these about? What do the wine and the cup refer to? What about the rose and the lip? and others.
<p/>

<p>
Maybe, it is obvious. The *wine* and the *cup* are referring to binge and having fun. On the other hand, rose is the symbol of lover in Persian poems and of course it has its own complivated means. Then, lip and rose could refer to *pleasure* and *carelessness* and of course *love*. It's all about seizing the present moment.
<p/>

Below, words repeated more than 10 times, have been shown.
<div/>

```{r}
library(ggplot2)
tidy_khayyam %>%
    count(word, sort = TRUE) %>%
    filter(n > 10) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip()
```

<div style="text-align: justify">

There are some guidelines which can separate the words based on their sentiments. For example positive words or negative words. One of these guidelines is ***bing***. 
<div/>

```{r}
bing_word_counts <- tidy_khayyam %>%
    inner_join(get_sentiments("bing")) %>%
    count(word, sentiment, sort = TRUE)
bing_word_counts

```

Here, these words have been visually shown.

```{r}
# This can be shown visually
bing_word_counts %>%
    group_by(sentiment) %>%
    top_n(10) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n, fill = sentiment)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~sentiment, scales = "free_y") +
    labs(y = "Contribution to sentiment",
         x = NULL) +
    coord_flip()
```

<div style="text-align: justify">

We can check *wordcloud* plot for Khayyam's poems. Size of words have been determined based on their frequency.
<div/>

```{r}
library(wordcloud)
tidy_khayyam %>%
  anti_join(custom_stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
```

# Topic modeling

<div style="text-align: justify">
<p>
Every document could be separated to different topics that each of them may have their own labels. Topic modeling is a method which can be used for this purpose. A popular topic modeling is **Latent Dirichlet allocation (LDA)**. Based on *LDA* each document is a mixture of topics and each topic is a mixture of words. In Khayyam's poems, we hypothesize that it contains two different topics; however we can consider more topics too. But, if you are dealing with a document that include several chapters, you can set number of chapters as number of topics. 
<p/>
<div/>

<p>
First of all, we must get the data ready to fit **LDA** model.
<p/>


```{r}
q = tidy_khayyam %>%
     count(gutenberg_id,word, sort = TRUE)
b = q %>%
     cast_dtm(gutenberg_id, word, n)
```

Now, it's time to fit *LDA* with k = 2 (two topics).

```{r}
ap_lda <- LDA(b, k = 2, control = list(seed = 1234))
ap_lda
```

<div style="text-align: justify">
After fitting the model, we can estimate the **per-topic-per-word probabilities, called β (“beta”)**, from the model. Needless to say, that these values indicate the probabilities of that term being generated from that topic. <div/>

```{r}
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics
```

<div style="text-align: justify">
<p>
The term "wine" has a 0.007 probability of being generated from topic 1, but a 0.01
probability of being generated from topic 2.
<p/>
<p>
Then we take a look at the 10 terms that are most common within each topic.
<p/>
<div/>

```{r}
ap_top_terms <- ap_topics %>%
     group_by(topic) %>%
     slice_max(beta, n = 10) %>% 
     ungroup() %>%
     arrange(topic, -beta)

ap_top_terms %>%
     mutate(term = reorder_within(term, beta, topic)) %>%
     ggplot(aes(beta, term, fill = factor(topic))) +
     geom_col(show.legend = FALSE) +
     facet_wrap(~ topic, scales = "free") +
     scale_y_reordered()
```

<div style="text-align: justify">

What does topic 1 say? the terms **"rose"**, **"lip"**, **"wine"**, **"thee"**. It seems that *Khayyam* is talking about relationship with lover, kiss and drinking a wine with a partner. 
What about topic 2? There are terms such as **"wine"**, **"hand"**, **"drink"** and **"grape"**. If you have read Khayyam's poems, you know that he mostly wrote and composed about holding a cup, drinking the wine and enjoying the life. On the other hand, it was a boom age of pottery in ancient times (almost 1000 years ago) in Iran. Khayyam believed that the bodies of died and buried people turn into soil and dust over time and roses grow from that dust.
He believed that the pottery we use are made from the soil and dust of dead people and one day, the pottery will be made from our soil and dust for next generations(e.g. hundred year later). Therefore, We should treat pottery with respect because it is made from other people's soil. Time is very very short and we should appreciate and enjoy the short moments of life.
<div/>

```{r}
beta_wide <- ap_topics %>%
     mutate(topic = paste0("topic", topic)) %>%
     pivot_wider(names_from = topic, values_from = beta) %>% 
     filter(topic1 > .001 | topic2 > .001) %>%
     mutate(log_ratio = log2(topic2 / topic1))
beta_wide
```

<div style="text-align: justify">
<p>
In this output, we see that the term "wine" is more likely to belong to topic 2. On the other hand, terms "cup" and "rose" are more likely to belong to topic 1. Based on the results, we can labels to each of topics, but we don't do that and leave it to the taste of the readers.
<p/>
<div/>

# Conclusion

<div style="text-align: justify">
<p>
We introduced the basics concepts of text mining. Clearly, we didn't delve into details. In a nutshell, we analyzed the Khayyam's poems. We saw that Khayyam believes in joy. I'll highly recommend you to read his poems and personally discover his mindset. If we want to summarize his thought and world view in one sentence, that sentence will be this:

> Life is short. Always choose happiness.

<p/>
<div/>