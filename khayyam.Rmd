---
title: "Khayyam"
author: "Reza A.Khoei"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

<div style="text-align: justify">

<p>
[Khayyam](https://en.wikipedia.org/wiki/Omar_Khayyam) was an Iranian astronomer, mathematician,philosopher and a poet , which is commonly known for his quatrains (short poems). He was almost unknown to whole world, till 19 century, but thanks to [**EdwardFitzGerald**](https://en.wikipedia.org/wiki/Edward_FitzGerald_(poet)), his poems were translated to English and published entitled [*Rubaiyat of Omar Khayyam*](https://en.wikipedia.org/wiki/Rubaiyat_of_Omar_Khayyam).
<p/>
<p>
His achievements in astronomy and mathematics such as [solar calender](https://en.wikipedia.org/wiki/Solar_calendar) and [cubic equation](https://en.wikipedia.org/wiki/Cubic_equation) are admirable, nonetheless, world realized who he really is, because of the hidden amazing philosophy in his poems. Discovery the hidden truth in his text poems made me motivated to do some analysis and document it for the others; that is exactly where the **text mining** methods come in. In text mining, the focus is on textual data and extraction of wisdom from it. To have some knowledge about text mining using *R*, you can refer to [this book](https://www.tidytextmining.com/) which is written by [Julia Silge](https://juliasilge.com/) and [David Robinson](http://varianceexplained.org/about/).
<p/>
<p>
Now that we have our tools, let's get ready and start our journey and float in the Khayyam's mind and find out what was going on in his mind and enjoy it.
<p/>
<div/>

# Call required packages

At first, the packages we need, should be installed and called.

```{r eval=FALSE, message=FALSE, warning=FALSE}
install.packages(tidyverse)
install.packages(tidytext)
install.packages(gutenbergr)
install.packages(topicmodels)
```


```{r message=FALSE}
library(tidyverse)
library(tidytext)
library(gutenbergr)
library(topicmodels)
```

# Download the data

So many books are accessible in the ***gutenbergr*** package. Every book has its own ***gutenberg_id*** and can be found via it. For more dertails you can refer to Help page of package. The ***gutenberg_id*** for Khayyam is ***246***. Let's take a look at it. 

```{r}
khayyam <- gutenberg_download(246)
khayyam <- khayyam %>% slice(-c(1:450, 1878:2131))
tidy_khayyam <- khayyam %>%
    unnest_tokens(word, text) %>%
    anti_join(stop_words)
tidy_khayyam
# The most common words in Khayyam's poems
tidy_khayyam %>%
    count(word, sort = TRUE)
```

```{r}
custom_stop_words <- bind_rows(tibble(word = c("ah","sans"),  
            lexicon = c("custom")), stop_words)

custom_stop_words
```

```{r}
tidy_khayyam <- khayyam %>%
    unnest_tokens(word, text) %>%
    anti_join(custom_stop_words)
tidy_khayyam
# The most common words in Khayyam's poems
tidy_khayyam %>%
    count(word, sort = TRUE)
```

```{r}
library(ggplot2)
tidy_khayyam %>%
    count(word, sort = TRUE) %>%
    filter(n > 10) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n)) +
    geom_col() +
    xlab(NULL) +
    coord_flip()
```

```{r}
bing_word_counts <- tidy_khayyam %>%
    inner_join(get_sentiments("bing")) %>%
    count(word, sentiment, sort = TRUE)
bing_word_counts
# This can be shown visually
bing_word_counts %>%
    group_by(sentiment) %>%
    top_n(10) %>%
    mutate(word = reorder(word, n)) %>%
    ggplot(aes(word, n, fill = sentiment)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~sentiment, scales = "free_y") +
    labs(y = "Contribution to sentiment",
         x = NULL) +
    coord_flip()
```

```{r}
library(wordcloud)
tidy_khayyam %>%
  anti_join(custom_stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))
# Letâ€™s do the sentiment analysis to tag positive and negative words
# using an inner join, then find the most common positive and negative words
library(reshape2)
tidy_khayyam %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)
```

```{r}
# Find out how much each word contributed to each sentiment

bing_word_counts <- tidy_khayyam %>%
    inner_join(get_sentiments("bing")) %>%
    count(word, sentiment, sort = TRUE) 
bing_word_counts
```

```{r}
# This can be shown visually
bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()
```

```{r}
q = tidy_khayyam %>%
     count(gutenberg_id,word, sort = TRUE)
q

b = q %>%
     cast_dtm(gutenberg_id, word, n)
```

```{r}
ap_lda <- LDA(b, k = 2, control = list(seed = 1234))
ap_lda
```

```{r}
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics
```

```{r}
ap_top_terms <- ap_topics %>%
     group_by(topic) %>%
     slice_max(beta, n = 10) %>% 
     ungroup() %>%
     arrange(topic, -beta)

ap_top_terms %>%
     mutate(term = reorder_within(term, beta, topic)) %>%
     ggplot(aes(beta, term, fill = factor(topic))) +
     geom_col(show.legend = FALSE) +
     facet_wrap(~ topic, scales = "free") +
     scale_y_reordered()
```

```{r}
library(tidyr)
beta_wide <- ap_topics %>%
     mutate(topic = paste0("topic", topic)) %>%
     pivot_wider(names_from = topic, values_from = beta) %>% 
     filter(topic1 > .001 | topic2 > .001) %>%
     mutate(log_ratio = log2(topic2 / topic1))
 
beta_wide
```

```{r}
ap_documents <- tidy(ap_lda, matrix = "gamma")
ap_documents
```
